---
layout: single
title: "인공지능입문 2주차 수업 정리"
---

## Page 3~6: 지능형 에이전트

### 1. 지능적이란?

해당 수업에서 지능적이라는 것은 **합리적이다**라고 정의합니다.

- **이유**: 인공지능에 대한 논의 4가지(인간적/합리적/사고중심적/행동중심적) 중에서 합리적인 행동을 하는 인공지능이 중요도가 높다고 판단했기 때문입니다.

### 2. 에이전트란?

- **에이전트(Agent)**: 감지기를 통해 환경을 지각하고, 작동기를 통해 환경에 동작을 수행하여 환경과 상호작용하는 존재입니다.
- 에이전트는 단순한 사고를 넘어서 자체적으로 행동하고 무언가 해낼 수 있는 능력을 가진 개체입니다.
  - **에이전트**: 환경과 상호작용하며 작동합니다.
  - **감지기(sensor)**
  - **환경(environment)**: 물리적 공간뿐만 아니라 인터넷 공간이나 소프트웨어 환경과 같은 가상 환경도 포함됩니다.
  - **지각(percept)**: 특정 시점에 에이전트가 감지기를 통해 인식하는 내용입니다.
  - **작동기(actuator)**
  - **동작(action)**: 사람으로 비유하자면, 감각기관은 눈, 코, 귀가 되고, 액츄에이터는 팔, 다리와 같습니다. 뇌나 중추신경이 동작을 결정합니다.

### 3. 지능형 에이전트

- **합리적인 의사결정**을 할 수 있는 인공지능 에이전트입니다.
  - **지각열(percept sequence)**: 에이전트가 특정 대상에 대해 지각한 내용들의 집합입니다.
    - 에이전트는 기존의 지식이나 지각열을 기반으로만 동작하며, 지각하지 않은 대상에 대해서는 동작하지 않습니다.
    - 완벽한 에이전트는 지각 가능한 대상에 대해 모든 가능한 지각열과 동작을 매칭시킬 수 있어야 합니다.
  - **자율주행자동차**: 주변에 많이 보이는 지능적인 에이전트는 자율 주행 자동차입니다.
    - 라이다, 레이더, 카메라, GPS 등의 센서를 사용하여 주변 환경을 인식하고 동작을 결정합니다.
  - **에이전트 함수**: 임의의 지각열을 하나의 동작으로 연결하는 수학적 개념입니다.
    - 일반적으로 추상적이고 수학적으로 묘사됩니다. 하지만 테이블 형태로 묘사할 수도 있습니다.
    - **에이전트 프로그램**: 에이전트 함수는 물리적 시스템에서 동작하는 구체적인 구현을 의미합니다.

## Page 7: 합리적 에이전트와 좋은 행동

### 1. 합리적인 에이전트

- **합리적인 에이전트**는 옳은 일을 하는 에이전트를 의미합니다.
  - **옳은 일**: 결과적으로 행동이 낳은 결과를 바탕으로 평가할 수 있습니다.
  - **옳은 일**을 할 때: 에이전트가 지각에 따라 동작을 수행하면, 환경의 상태가 바람직할 경우에 옳은 일을 한다고 정의합니다.

### 2. 성과 측도

- 성과 측도는 환경의 임의 상태열의 바람직함을 평가하는 지표입니다.
  - **성과 측도의 설계 기준**: 환경 내에서 에이전트가 달성하고자 하는 목표에 기반하여 행동해야 합니다.

## Page 8: 합리성과 성과 측도

### 1. 합리적 기준

- **성과 측도**: 에이전트가 의도한 행동의 성공 기준입니다.
- **사전 지식**: 환경에 대한 에이전트의 내장된 지식입니다.
- **동작(들)**: 에이전트가 수행 가능한 행동의 세트입니다.
- **지각(열)**: 지금까지의 지각 열입니다.

### 2. 합리적 에이전트의 정의

- 합리적인 에이전트는 각 가능한 지각열에 대해 자신의 지각열과 사전 지식에 기반하여 성과 측정치를 극대화할 수 있는 동작을 선택해야 합니다.

### 3. 합리적 에이전트의 예시

- **로봇 청소기**
  - **성과 측도**: 깨끗한 사각형은 1점 획득
  - **사전 지식**: 전체 영역의 지리, 사각형 하나 이동 가능, 사각형 외부 이동 불가 등
  - **동작**: 오른쪽 이동, 왼쪽 이동, 먼지 흡입, 정지 등
  - **지각**: 에이전트의 위치, 해당 위치에 먼지 유무 인식 등

## Page 9: 합리적 에이전트의 주요 능력

### 1. 설계 목표

- 완벽한 에이전트가 아닌, 현재까지의 지각열을 기반으로 합리적인 행동을 하는 것을 목표로 합니다.

### 2. 합리성과 완벽함

- **합리성**: 기대 성과를 극대화하려고 합니다.
- **완벽함**: 실제 성과를 극대화하려고 합니다.

### 3. 기대 성과를 극대화하기 위해서

- **정보 수행**: 지각들을 수정하기 위한 행위입니다.
- **학습 능력**: 지각 정보로부터 최대한 많은 것을 배우는 능력입니다.
- **자율성 능력**: 자신의 부분적이나 부정확한 사전 지식을 학습을 통해 보완할 수 있는 능력입니다.

### 4. 주의사항

- 사전 지식 없이 완전한 자율성을 요구하는 경우는 매우 드뭅니다.
  - 이 경우 에이전트는 무작위적인 행동에 의존할 수 있으며, 설계자의 초기 지식 및 학습 능력 주입이 필요합니다.
  - 에이전트가 스스로 독립적으로 행동할 수 있도록 만드는 것이 중요합니다.

## Page 10~11: 과제 환경(Task Environment)

### 1. 과제 환경과 에이전트

- **과제 환경(task environment)**: 문제(problem)입니다.
- **합리적인 에이전트**: 해답(solution)입니다.

### 2. PEAS

- **Performance**
- **Environment**
- **Actuators**
- **Sensors**

  - 과제 환경은 PEAS 서술을 통해 완전 표현이 가능합니다.

### 3. 택시 기사의 예시

![택시 기사 예시](https://prod-files-secure.s3.us-west-2.amazonaws.com/9e0fcb96-cbd0-499f-add8-257d38028f67/9643a0b4-eec2-4271-a869-105cc3a81aad/image.png)

### 4. 기타 예시

![기타 예시](https://prod-files-secure.s3.us-west-2.amazonaws.com/9e0fcb96-cbd0-499f-add8-257d38028f67/edde1692-4435-4655-887a-f27e73f98f62/image.png)

## Page 12~15: 과제 환경의 속성(Properties)

### 1. 완전 관측 가능(fully observable) VS 부분 관측 가능(partially observable)

- 에이전트가 매 순간 환경의 완전한 상태에 접근 가능한지, 부분적으로 가능한지의 여부입니다.

### 2. 단일 에이전트(single agent) VS 다중 에이전트(multiagent)

- 에이전트가 환경에서 단독으로 동작하는지, 여러 개의 에이전트가 함께 동작하는지의 문제입니다.

### 3. 경쟁적(competitive) VS 협력적(cooperative)

- 에이전트가 하나가 아닌 여럿일 때 서로 경쟁하는 구도인지, 협력하는 구도인지의 여부입니다.

### 4. 결정론적(deterministic) VS 비결정론적(non-deterministic)/확률론적(stochastic)

- 환경의 다음 상태가 현재 상태와 에이전트가 수행한 행동에 의해 완전히 결정되는지의 여부입니다.
  - **확률론적**: 비결정론적 문제로 취급 가능
  - **비결정론적**: 수치를 다루지 않는 경우
  - **준-동적(semi-dynamic)**: 에이전트의 성과 측정이 시간 흐름에 영향을 받을 때

### 5. 일화적(episodic) VS 순차적(sequential)

- 에이전트의 경험이 원자적인 에피소드로 나뉘고, 각각의 행동 선택이 다른 에피소드가 아닌 한 에피소드에만 의존하는지의 여부입니다.

### 6. 정적(static) VS 동적(dynamic)

- 환경의 상태가 시간에 따라 변하지 않는지, 변하는지의 여부입니다.

### 7. 환경 예시

- **단일 에이전트**: 택시, 로봇 청소기, 자동화된 가정용 로봇, 트랙터, 무인기
- **다중 에이전트**: 자율주행 자동차들, 드론

### 8. 예시: 자율주행 자동차

- **경쟁적**: 자동차가 서로 간섭하는 상황
- **협력적**: 교통 시스템의 효율적인 상호작용

## 2주차 - 1 수업 복습

- **정적**: 다음 동작에 대한 계획을 세울 때 환경이 변하지 않음
- **동적**: 다음 동작에 대한 계획을 세울 때 환경이 변함
- **준동적**: 에이전트가 다음 동작에 대한 계획을 세울 때 환경의 변화가 영향을 줌
- 시간의 흐름에 있어서 에이전트가 그대로 있는데 상황이 변하는지/아닌지에 따라 나눔
- **이미지 분석**:
    - **고정된 이미지**: 이미지라는 환경이 변화하지 않기에 고정적이라고 판단
    - **변화가 있는 이미지**: 환경 자체가 이미지가 되어서 이미지가 확대되거나 축소될 때 환경이 달라진다고 판단. 영상과 같은 경우는 프레임 단위로 계속해서 환경이 변하기에 결과도 달라짐

### page 18~22 : 에이전트의 유형

---

**4가지 기본 에이전트의 유형**

1. **단순 반사 에이전트**
    1. 에이전트가 지금까지 지각해온 이력을 고려하지 않고, 단순히 현재 당장 지각한 상태에 기반하여 행동함
    2. 과거의 영향을 받지 않고 행동함
    3. 센서에서 엑추에이터까지의 판단 모듈 사이에는 조건-동작 규칙이 적용됨
        1. **조건-동작(condition-action) 규칙**: 상태(조건)를 행동에 매핑시키는 규칙 
            - 예) 더러우면 → 청소, 깨끗하면 → 청소 X
    4. **단점**
        - 에이전트의 환경을 완전하게 관찰 가능한 경우에만 적용 가능. 부분적으로 관측 가능한 환경에서는 무한루프에 빠질 수 있음
            - 예) 로봇청소기가 좁은 구역에 있을 경우 스스로 빠져나오기 어렵다
        - 지능이 매우 한정적이고, 상태의 비지각적인 부분에 대한 지식이 없음
        - 환경에 변화가 생길 경우 변화에 대한 규칙을 매번 업데이트해야 함

2. **모형 기반 반사 에이전트**
    1. 모형을 통해 실제 세계에 대한 지식을 얻고 그걸 활용하는 에이전트
    2. 단순 반사와는 다르게 모형, 모델을 생성해 놓고 그걸 기반으로 활용함
    3. **장점**
        - 전체가 아닌 부분적으로 정보를 얻을 수 있고 관찰 가능한 환경에도 적용 가능
        - 모델과 모형을 가지고 있기 때문에 단순 반사와는 다르게 처리가 가능
    4. **내부 상태**: 외부 환경에 대한 정보를 저장하고, 현재 상태와 과거 정보, 추론 및 예측 정보들을 담아 복잡한 세계를 표상함. 공간과 시간적인 정보도 담아놓고 처리함. 학습과는 다른 개념임
    5. **감지기 모형(sensor model)** + **전이모형(transition model)**
        - **감지기 모형**: 내부의 상태를 갱신하기 위해서 세계의 상태가 지각으로 반영되는 방법
        - **전이 모형**: 에이전트가 수행한 동작들의 효과와 에이전트와 독립적으로 세계가 진화하는 방법에 대한 것

    **단순 반사 에이전트 vs 모형 기반 반사 에이전트**
    
    - 예) 온도가 30도 이상이면 에어컨을 튼다. 20도 이하면 에어컨을 끈다
    - 예) 온도가 30도 이상이면 에어컨을 튼다. 온도가 점점 내려가면 에어컨의 세기를 줄인다…?

3. **목표 기반 에이전트**
    1. 모델 기반 에이전트의 기능을 확장하여 목표(원하는 상황, 바람직한 상황) 정보를 사용하는 에이전트
    2. 목표 정보에 따른 목표와의 거리를 좁히면서 목표 상태에 도달할 수 있는 다양한 선택지를 가지고 있음
        1. 행동과 그에 따른 결과와 다시 또 그에 따른 경우의 수들을 계산해서 적합한 선택지를 선택해 작동함
    3. 탐색 및 계획 수립으로 목표 달성에 필요한 일련의 동작열(action sequence)을 찾음
        - 탐색: 목표 상태로 도달하기 위해서 탐색하는 과정
        - 계획 수립: 탐색과정을 통해 결과를 도달하기 위한 계획 수립

4. **효용 기반 에이전트**
    1. 등장 배경: 목표 기반 에이전트가 수행 목표를 선택할 때, 목표 설정이나 목표 달성에 있어서 문제가 발생하는 소지가 있어서 해결하기 위해 제안됨
    2. 목표 기반 에이전트와의 차이점: (목표/비목표) 상태만 구분하는 것과 달리, 목표가 무엇인지를 구분할 뿐만 아니라, 그 목표에 도달 가능한 최적의 방법을 선택해 행동함
    3. **효용 함수**: 어떤 상태에 대한 만족도를 일정한 수치화로 나타내는 함수
    4. **효용성**: 행동의 결과가 얼마나 만족스러운지를 의미함
    5. **합리적인 효용 기반 에이전트**: 행동 결과에 대한 기대 효용을 극대화하는 방향으로 행동을 선택함
    6. 적절한 효용성을 유지하고, 목표를 달성하기 위해 환경에 대한 모델을 만들어서 추적함. 인식, 표현, 추론 및 학습 관련 연구를 포함한 여러 작업을 처리함

### Page 23~24. 기본 에이전트 확장: 학습하는 에이전트

---

**학습하는 에이전트의 등장 배경**: 기본 4가지 에이전트의 유형을 동작 선택의 규칙과 방법에 차이가 있지만 시간이 지나도 과거의 경험을 통해서 스스로 학습하고 개선할 수는 없었음

→ 튜링은 지능적인 기계를 프로그래밍하는데, 학습하는 기계를 구축하고 가르치는 것이 필요함을 주장함

**학습하는 에이전트 (Learning agents)**: 학습 능력을 갖추고 있어 초기에 제공된 지식과 과거 경험을 통해 학습을 진행함. 학습 결과에 따라 행동하고 적응할 수 있는 에이전트

**학습 에이전트의 개념 요소**

- **수행 요소**: 에이전트가 실제로 환경에서 행동을 수행하는 부분임. 현재 지식과 상태를 기반으로 어떻게 행동할 것인지를 결정함
- **비평(Critic)**: 수행 요소가 선택한 행동에 대한 결과를 평가해서 에이전트가 수행 기준에 의해 적절하게 성종적으로 행동하는지 피드백, 비평을 제공함
- **학습 요소**: 학습의 진척을 담당함. 비평을 통해 피드백을 받아 에이전트의 행동을 개선함. 수행 요소에 변화도 유도함
    - 이 과정에서 에이전트는 더 나은 행동 전략을 학습할 수 있음
- **문제 생성기**: 에이전트가 새롭고 배울 점 있는 다양한 경험을 쌓을 수 있도록 새로운 도전을 제공함
    - 에이전트가 더 많은 상황을 학습할 수 있음

### Page 25. 에이전트 프로그램 구성요소와 표현방식

---

**에이전트 프로그램의 구성요소**

- 에이전트들은 다양한 구성 요소로 이루어져 있음
- 에이전트의 구성요소는 프로그램 안에서 여러 가지 방식으로 표현되고, 질문에 답함
- **질문의 예**
    - 세계는 지금 어떤 모습인가?
    - 지금 할 동작은 무엇인가?
    - 이 동작이 세상에 어떤 영향을 미치는가?

**에이전트의 표현방식**

1. **원자적 표현 (Atomic Representation)**: 더 이상 분해되지 않는, 쪼개지지 않는 하나의 상태를 말함. 하나의 원자 안에 추가적인 내부 구조가 없음
2. **분해된 표현 (Factored Representation)**: 하나의 상태를 고정된 개수와 종류의 변수나 특성으로 분해함. 변수들은 각각의 값을 가짐. 하나의 상태를 특성값들의 벡터로 구성됨
3. **구조적 표현 (Structured Representation)**: 객체와 그들의 다양하고 가변적인 관계를 명시적으로 서술한 것을 말함

### 2주차 실습 - 자료구조 기초

---

1. **스택 (Stack)**
    1. **LIFO(Last In, First Out)**: 가장 마지막에 들어간 데이터가 가장 먼저 빠져나가는 구조
    2. 데이터를 넣는 것을 `push`, 빼내는 것을 `pop`이라고 부름
    3. 파이썬의 스택 구조는 기본적으로 단순 리스트만 활용하여 구현이 가능함
    
    ```python
    stack = []
    
    stack.append(1)
    stack.append(2)
    stack.append(3)
    
    print(stack)
    
    stack.pop()
    print(stack)
    ```
    
    **결과**
    
    ```plaintext
    [1, 2, 3]
    [1, 2]
    ```
    
    4. 리스트만으로도 스택 구현이 가능하다
    5. 하지만, 속도가 좀 더 빠른 스택 구조를 만들 시 파이썬 `collections`의 `deque` 모듈 활용 추천
    
    - **deque** (double-ended queue: 큐 앞뒤 삽입/삭제 가능)는 양쪽 끝에서 빠르게 요소를 추가하고 제거할 수 있는 자료구조로, 스택과 큐를 구현하는 데 유용함
    - 리스트보다 요소의 추가 및 제거가 더 효율적이며, 큐나 스택 작업을 수행할 때 성능 이점이 있음
    
    ```python
    from collections import deque
    
    stack = deque()
    data = [1, 2, 3, 4, 5]
    for i in data:
        stack.append(i)
    
    print(stack)
    
    stack.pop()
    
    print(stack)
    ```
    
    **결과**
    
    ```plaintext
    deque([1, 2, 3, 4, 5])
    deque([1, 2, 3, 4])
    ```
    
2. **큐 (Queue)**
    1. **FIFO(First In, First Out)**: 가장 먼저 들어간 데이터가 가장 먼저 빠져나가는 구조
    2. 큐에 자료를 넣는 것을 `enqueue`, 빼내는 것은 `dequeue`라고 부름
    3. 파이썬에서는 `deque` (double-ended queue: 큐 앞뒤 삽입/삭제 가능)를 사용
        
    ```python
    from collections import deque
    
    list = [1, 2, 3, 4, 5]
    queue = deque(list)
    
    queue.append(6)
    print(queue)
    
    queue.popleft()
    print(queue)
    ```
    
    **결과**
    
    ```plaintext
    deque([1, 2, 3, 4, 5, 6])
    deque([2, 3, 4, 5, 6])
    ```
    
    4. 파이썬의 `queue` 라이브러리에서 `Queue` 모듈을 사용해도 큐를 구현할 수 있지만, 실습 시 속도 측면이나 사용 용이성 측면에서 `deque` 모듈 사용을 추천함
        1. `queue.Queue`는 큐 내부 요소에 직접 접근/출력 기능을 제공하지 않음. 이 때문에 `get`으로 하나하나 빼내는 불편한 방식을 사용해야 함
        2. (다만, `queue` 모듈이 무조건 나쁜 것이 아니라 빠르고 자주 데이터를 넣고 빼야 하는 멀티 스레드 상황에서 안전성이 높다는 장점이 존재함)
        
        ```python
        from queue import Queue
        
        que = Queue()
        que.put(3)
        que.put(6)
        que.put(9)
        
        print(que)
        
        while not que.empty():
            print(que.get())
        ```
        
        **결과**
        
        ```plaintext
        <queue.Queue object at 0x0000029B3579C810>
        3
        6
        9
        ```
        
3. **우선순위 큐 (Priority Queue)**
    1. 우선순위 큐는 FIFO 특성을 가진 일반 큐와 달리, 추가 순서와 무관하게 우선순위가 높은(가장 작은 값)을 제거하는 특이한 자료구조
    2. 앞서 활용한 `queue` 라이브러리 내 `PriorityQueue` 모듈 활용 가능
    
    ```python
    from queue import PriorityQueue
    
    pque = PriorityQueue()
    pque.put(4)
    pque.put(1)
    pque.put(7)
    pque.put(9)
    
    while not pque.empty():
        print(pque.get())
    ```
    
    **결과**
    
    ```plaintext
    1
    4
    7
    9
    ```
    
    3. 파이썬의 priority queue는 `heapq` 모듈로도 활용 가능
    
    ```python
    import heapq
    
    heap = []
    
    heapq.heappush(heap, (4, 'task 4'))
    heapq.heappush(heap, (4, 'task 1'))
    heapq.heappush(heap, (4, 'task 7'))
    heapq.heappush(heap, (4, 'task 9'))
    
    print(heap)
    
    while heap:
        print(heapq.heappop(heap))
    ```
    
    **결과**
    
    ```plaintext
    [(4, 'task 1'), (4, 'task 4'), (4, 'task 7'), (4, 'task 9')]
    (4, 'task 1')
    (4, 'task 4')
    (4, 'task 7')
    (4, 'task 9')
    ```


---

